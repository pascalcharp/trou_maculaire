{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn import metrics\n",
    "from IPython.display import display, Markdown, Latex\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Chargement et prétraitement des données\n",
    "\n",
    "### Chargement\n",
    "\n",
    "Le données proviennent de [ce dépôt.](https://www.kaggle.com/datasets/mathieugodbout/oct-postsurgery-visual-improvement)\n",
    "\n",
    "L'ensemble de test ne sera jamais employé dans aucune étape d'entraînement.  Par-contre, pour la régression logistique, l'ensemble de validation et l'ensemble d'entraînement seront fusionnés.\n",
    "\n",
    "### Prétraitement\n",
    "\n",
    "- Les données manquantes seront remplacées par la moyenne de la variable.\n",
    "- Le sexe est codé comme 1-2. Il sera recodé comme 0-1 afin que toutes les variables soient mises à la même échelle.\n",
    "- Lors des étapes d'entraînement on va normaliser les variables numériques selon leur score Z afin qu'elles soient toutes N(0, 1)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Statistiques de l'ensemble d'entraînement (pour la régression logistique) vs l'ensemble test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "|    |   age |   sex |   pseudophakic |   mh_duration |   elevated_edge |   mh_size |   VA_baseline |   VA_6months | responder   |\n|---:|------:|------:|---------------:|--------------:|----------------:|----------:|--------------:|-------------:|:------------|\n|  0 |    60 |     2 |              0 |        9      |               0 |       252 |             0 |           71 | True        |\n|  1 |    68 |     2 |              1 |       10.3125 |               0 |       336 |            41 |           78 | True        |\n|  2 |    73 |     1 |              0 |        5      |               1 |       287 |            43 |           76 | True        |\n|  3 |    70 |     1 |              1 |        3      |               1 |       144 |            56 |           80 | True        |\n|  4 |    68 |     2 |              1 |        9      |               1 |       152 |            63 |           83 | True        |\n|  5 |    66 |     2 |              0 |       10      |               0 |       160 |            63 |           69 | False       |\n|  6 |    62 |     2 |              0 |       13      |               1 |       184 |            36 |           37 | False       |\n|  7 |    83 |     2 |              0 |       10      |               1 |       355 |            59 |           63 | False       |\n|  8 |    72 |     1 |              1 |       21      |               1 |       191 |            68 |           62 | False       |\n|  9 |    65 |     2 |              0 |        9      |               1 |       240 |            41 |           52 | False       |\n| 10 |    69 |     2 |              0 |       16      |               1 |       212 |            69 |           49 | False       |\n| 11 |    80 |     1 |              0 |       13      |               1 |       248 |            65 |           72 | False       |\n| 12 |    63 |     2 |              0 |        8      |               1 |       216 |            62 |           71 | False       |\n| 13 |    76 |     1 |              0 |        8      |               1 |       144 |            75 |           70 | False       |\n| 14 |    58 |     2 |              0 |        4      |               0 |       288 |            43 |           63 | True        |\n| 15 |    74 |     2 |              0 |       15      |               1 |       520 |            40 |           63 | True        |\n| 16 |    63 |     2 |              0 |       12      |               1 |       424 |            40 |           63 | True        |"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chemin = \"~/PycharmProjects/trou_maculaire_regression_logistique/data/\"\n",
    "\n",
    "def get_data_from_files(chemin, fname):\n",
    "    df = pd.DataFrame()\n",
    "    for name in fname:\n",
    "        file = chemin + name\n",
    "        df = pd.concat([df, pd.read_csv(file)])\n",
    "\n",
    "    df.drop(['id', 'VA_2weeks', 'VA_3months', 'VA_12months'], inplace=True, axis=1)\n",
    "\n",
    "    #df['VA_baseline'].replace(0, np.nan, inplace=True)\n",
    "    df['VA_baseline'].fillna(df['VA_baseline'].mean(), inplace=True)\n",
    "\n",
    "    df.replace(-9, np.nan, inplace=True)\n",
    "    df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "    df['responder'] = (df['VA_6months'] - df['VA_baseline']) >= 15\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "df_test = get_data_from_files(chemin, [\"clinical_data_test.csv\"])\n",
    "display(Markdown(df_test.to_markdown()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Vue d'ensemble des données de l'ensemble test, après prétraitement"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "|             |     Mean |      SDev |\n|:------------|---------:|----------:|\n| age         |  68.8235 |   6.9213  |\n| mh_duration |  10.3125 |   4.49609 |\n| mh_size     | 256.059  | 104.435   |\n| VA_baseline |  50.8235 |  18.1633  |\n| VA_6months  |  66      |  11.7739  |"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_continuous_data_descriptive_stats(df):\n",
    "    \"\"\"\n",
    "    Construit un dataframe décrivant la moyenne et l'écart-type des variables continues du modèle clinique\n",
    "    :param df: df d'entrainement ou de test fourni sur Kaggle par Mathieu Godbout\n",
    "    :return: Un dataframe 5X2 contenant une colonne des moyennes et une colonne des écarts-type pour l'âge, la durée, le diamètre du trou, l'acuité visuelle de base et l'acuité visuelle à 6 mois.\n",
    "    \"\"\"\n",
    "    df_cont = df.drop(['sex', 'pseudophakic', 'elevated_edge', 'responder'], axis=1)\n",
    "    stats_cont = pd.DataFrame([df_cont.mean(axis=0, skipna=True), df_cont.std(axis=0, skipna=True)]).transpose()\n",
    "    stats_cont.columns = ['Mean', 'SDev']\n",
    "    #stats_cont = stats_cont.round(decimals=0)\n",
    "    return stats_cont\n",
    "\n",
    "\n",
    "test_set_continuous_data_descriptive_stats = get_continuous_data_descriptive_stats(df_test)\n",
    "display(Markdown(test_set_continuous_data_descriptive_stats.to_markdown()))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Résultats de la table 1, pour l'ensemble test et les données numériques\n",
    "\n",
    "- Il y a une différence de 1 dans la SD de mh_duration par-rapport aux résultats de l'article\n",
    "- On a 54 pour VA_baseline alors que dans l'article la valeur de 51 est rapportée.  Toutefois, une des valeurs de ce set était 0.  Est-ce une observation clinique adéquate ou une donnée manquante ayant été mal saisie?  Ici nous l'avons remplacée par la moyenne."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "|                  |   number |   per_cent |\n|:-----------------|---------:|-----------:|\n| F                |       12 |         71 |\n| M                |        5 |         29 |\n| lens_absent      |       13 |         76 |\n| lens_present     |        4 |         24 |\n| elevated_edge    |       13 |         76 |\n| no_elevated_edge |        4 |         24 |\n| non_responder    |        9 |         53 |\n| responder        |        8 |         47 |"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test_cat = df_test.drop(['age', 'VA_baseline', 'VA_6months', 'mh_duration', 'mh_size'], axis=1)\n",
    "\n",
    "def get_categorical_variable_descriptive_stats(df_cat, col_name, cmap):\n",
    "    cat_stats = df_cat[col_name].value_counts()\n",
    "    cat_stats.rename(cmap, inplace=True)\n",
    "    cat_stats.rename('number', inplace=True)\n",
    "    cat_proportions = df_cat[col_name].value_counts(normalize=True)*100\n",
    "    cat_proportions.rename(cmap, inplace=True)\n",
    "    cat_proportions.rename('per_cent', inplace=True)\n",
    "    cat_stats = pd.concat([cat_stats, cat_proportions], axis=1)\n",
    "    cat_stats = cat_stats.round(decimals=0)\n",
    "    return cat_stats\n",
    "\n",
    "def get_categorical_data_descriptive_stats(df_cat):\n",
    "    return pd.concat([get_categorical_variable_descriptive_stats(df_cat, 'sex', {1:'M', 2:'F'}),\n",
    "                      get_categorical_variable_descriptive_stats(df_cat, 'pseudophakic', {0:'lens_absent', 1:'lens_present'}),\n",
    "                      get_categorical_variable_descriptive_stats(df_cat, 'elevated_edge', {0:'no_elevated_edge', 1:'elevated_edge'}),\n",
    "                      get_categorical_variable_descriptive_stats(df_cat, 'responder', {0:'non_responder', 1:'responder'})\n",
    "        \n",
    "    ])\n",
    "\n",
    "test_set_categorical_data_stats = get_categorical_data_descriptive_stats(df_test_cat)\n",
    "display(Markdown(test_set_categorical_data_stats.to_markdown()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Résultats de la table 1 pour les données catégoriques de l'ensemble test\n",
    "\n",
    "- On a correspondance pour le sexe, la présence d'une lentille implantée, et le nombre de répondeurs.\n",
    "- La catégorie \"rebord élevé\" n'apparait pas dans l'article alors qu'elle est dans le modèle clinique.  Pourquoi?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n"
     ]
    }
   ],
   "source": [
    "df_train_lr = get_data_from_files(chemin, ['clinical_data_train.csv', 'clinical_data_val.csv'])\n",
    "print(len(df_train_lr))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "|    |   age |   sex |   pseudophakic |   mh_duration |   elevated_edge |   mh_size |   VA_baseline |   VA_6months | responder   |\n|---:|------:|------:|---------------:|--------------:|----------------:|----------:|--------------:|-------------:|:------------|\n|  0 |    73 |     2 |              0 |        3      |        1        |       336 |            58 |           78 | True        |\n|  1 |    69 |     2 |              0 |       47      |        1        |       552 |            33 |           71 | True        |\n|  2 |    67 |     2 |              0 |        8      |        1        |       761 |            10 |           77 | True        |\n|  3 |    56 |     2 |              0 |        9      |        1        |       467 |            42 |           77 | True        |\n|  4 |    49 |     2 |              0 |        7      |        1        |       320 |            61 |           83 | True        |\n|  5 |    61 |     1 |              0 |        8      |        1        |       153 |            66 |           83 | True        |\n|  6 |    77 |     1 |              1 |        7      |        1        |       518 |            53 |           74 | True        |\n|  7 |    79 |     2 |              1 |       11      |        1        |       671 |            53 |           78 | True        |\n|  8 |    69 |     2 |              1 |        7      |        1        |       264 |            48 |           78 | True        |\n|  9 |    72 |     2 |              0 |       19      |        1        |       133 |            58 |           75 | True        |\n| 10 |    62 |     2 |              1 |        4      |        1        |       645 |            35 |           78 | True        |\n| 11 |    55 |     2 |              1 |        9      |        1        |       411 |            48 |           78 | True        |\n| 12 |    65 |     2 |              0 |       21      |        1        |       378 |            48 |           75 | True        |\n| 13 |    66 |     1 |              0 |       11.1782 |        1        |       319 |            63 |           78 | True        |\n| 14 |    50 |     1 |              0 |       12      |        1        |       240 |            58 |           80 | True        |\n| 15 |    64 |     2 |              0 |        7      |        1        |       352 |            59 |           80 | True        |\n| 16 |    69 |     2 |              1 |        2      |        1        |       289 |            59 |           74 | True        |\n| 17 |    66 |     2 |              0 |        7      |        1        |       208 |            52 |           74 | True        |\n| 18 |    58 |     2 |              0 |        4      |        0        |        88 |            49 |           70 | True        |\n| 19 |    48 |     2 |              0 |        7      |        1        |       808 |            36 |           78 | True        |\n| 20 |    68 |     2 |              0 |       18      |        1        |       208 |            52 |           70 | True        |\n| 21 |    72 |     2 |              0 |        4      |        1        |       363 |            36 |           80 | True        |\n| 22 |    90 |     1 |              0 |       17      |        1        |       451 |            41 |           78 | True        |\n| 23 |    65 |     2 |              0 |       12      |        1        |       230 |            58 |           74 | True        |\n| 24 |    78 |     1 |              0 |        7      |        1        |       108 |            63 |           68 | False       |\n| 25 |    61 |     2 |              0 |        9      |        1        |       368 |            53 |           56 | False       |\n| 26 |    76 |     2 |              0 |       11      |        1        |       183 |            63 |           50 | False       |\n| 27 |    66 |     2 |              0 |       10      |        1        |       262 |            57 |           59 | False       |\n| 28 |    73 |     1 |              0 |        7      |        1        |       248 |            50 |           63 | False       |\n| 29 |    70 |     2 |              0 |       11      |        1        |       376 |            59 |           64 | False       |\n| 30 |    68 |     2 |              0 |       12      |        1        |       342 |            62 |           65 | False       |\n| 31 |    60 |     2 |              0 |       39      |        1        |       512 |            43 |           48 | False       |\n| 32 |    60 |     1 |              0 |       18      |        0        |       232 |            79 |           10 | False       |\n| 33 |    67 |     2 |              0 |        4      |        1        |       143 |            66 |           67 | False       |\n| 34 |    64 |     2 |              0 |       10      |        1        |       112 |            68 |           67 | False       |\n| 35 |    64 |     2 |              0 |        8      |        1        |       162 |            49 |           58 | False       |\n| 36 |    66 |     1 |              1 |        8      |        0        |       157 |            57 |           63 | False       |\n| 37 |    60 |     1 |              0 |       13      |        1        |       176 |            65 |           67 | False       |\n| 38 |    70 |     1 |              0 |       10      |        1        |       433 |            51 |           56 | False       |\n| 39 |    65 |     2 |              0 |        5      |        1        |       496 |            57 |           51 | False       |\n| 40 |    62 |     2 |              0 |        5      |        1        |       435 |            64 |           63 | False       |\n| 41 |    56 |     1 |              0 |        8      |        1        |       316 |            48 |           56 | False       |\n| 42 |    64 |     2 |              0 |        8      |        0        |       248 |            43 |           51 | False       |\n| 43 |    67 |     2 |              0 |       18      |        0        |       202 |            36 |           41 | False       |\n| 44 |    73 |     2 |              0 |        9      |        0        |       264 |            62 |           69 | False       |\n| 45 |    66 |     2 |              0 |        4      |        1        |       316 |            51 |           36 | False       |\n| 46 |    68 |     2 |              0 |       17      |        1        |       465 |            49 |           60 | False       |\n| 47 |    64 |     2 |              0 |       12      |        1        |       208 |            56 |           63 | False       |\n| 48 |    67 |     2 |              0 |        7      |        1        |       434 |            50 |           43 | False       |\n| 49 |    62 |     2 |              0 |       12      |        1        |       539 |            36 |           50 | False       |\n| 50 |    73 |     1 |              1 |       11      |        1        |       160 |            60 |           68 | False       |\n| 51 |    71 |     2 |              0 |        7      |        1        |       380 |            49 |           60 | False       |\n| 52 |    66 |     2 |              0 |       13      |        1        |       425 |            60 |           70 | False       |\n| 53 |    56 |     2 |              0 |        6      |        1        |       176 |            70 |           78 | False       |\n| 54 |    82 |     1 |              0 |        6      |        1        |       229 |            65 |           70 | False       |\n| 55 |    68 |     1 |              0 |        6      |        1        |        80 |            63 |           76 | False       |\n| 56 |    67 |     2 |              0 |       13      |        0        |       189 |            70 |           71 | False       |\n| 57 |    66 |     2 |              0 |        2      |        1        |        96 |            65 |           76 | False       |\n| 58 |    39 |     2 |              1 |        6      |        1        |       280 |            65 |           76 | False       |\n| 59 |    71 |     2 |              1 |        3      |        1        |       400 |            79 |           80 | False       |\n| 60 |    74 |     2 |              0 |        6      |        1        |       440 |            68 |           72 | False       |\n| 61 |    69 |     1 |              0 |       11.1782 |        1        |       207 |            60 |           70 | False       |\n| 62 |    69 |     2 |              0 |        4      |        0.901961 |       270 |            65 |           70 | False       |\n| 63 |    63 |     1 |              0 |       21      |        1        |       240 |            63 |           70 | False       |\n| 64 |    67 |     1 |              1 |       12      |        1        |       474 |            70 |           71 | False       |\n| 65 |    73 |     1 |              0 |       13      |        1        |       223 |            63 |           75 | False       |\n| 66 |    70 |     2 |              0 |        5      |        1        |       498 |            40 |           65 | True        |\n| 67 |    57 |     1 |              0 |       24      |        1        |       592 |            10 |           63 | True        |\n| 68 |    66 |     2 |              0 |        8      |        1        |       122 |            40 |           69 | True        |\n| 69 |    67 |     2 |              0 |       10      |        1        |       712 |            10 |           53 | True        |\n| 70 |    72 |     2 |              0 |        9      |        1        |       696 |            43 |           59 | True        |\n| 71 |    65 |     2 |              0 |        7      |        1        |       288 |            34 |           57 | True        |\n| 72 |    64 |     2 |              0 |        2      |        1        |       240 |            40 |           61 | True        |\n| 73 |    69 |     2 |              0 |       15      |        1        |       572 |            43 |           67 | True        |\n| 74 |    78 |     2 |              1 |        7      |        0        |       387 |            43 |           67 | True        |\n| 75 |    69 |     2 |              1 |       75      |        1        |       627 |            10 |           60 | True        |\n| 76 |    63 |     2 |              0 |       16      |        1        |       672 |            43 |           69 | True        |\n| 77 |    70 |     2 |              0 |        9      |        1        |       568 |            41 |           64 | True        |\n| 78 |    64 |     2 |              0 |        7      |        1        |       486 |            21 |           69 | True        |\n| 79 |    66 |     2 |              0 |        4      |        1        |       344 |            40 |           59 | True        |\n| 80 |    78 |     1 |              1 |        9      |        1        |       368 |            21 |           50 | True        |\n| 81 |    77 |     2 |              0 |       24      |        1        |       486 |            10 |           41 | True        |\n| 82 |    69 |     2 |              0 |       38      |        1        |       513 |            49 |           68 | True        |\n|  0 |    67 |     1 |              0 |        5      |        1        |       240 |            49 |           72 | True        |\n|  1 |    64 |     1 |              0 |       10      |        1        |       168 |            58 |           76 | True        |\n|  2 |    64 |     2 |              0 |        6      |        1        |       376 |            48 |           70 | True        |\n|  3 |    76 |     2 |              1 |        5      |        1        |       302 |            58 |           78 | True        |\n|  4 |    62 |     1 |              0 |        8      |        1        |       325 |            40 |           70 | True        |\n|  5 |    55 |     2 |              0 |       14      |        1        |       164 |            61 |           79 | True        |\n|  6 |    65 |     2 |              0 |       24      |        1        |       527 |            47 |           49 | False       |\n|  7 |    65 |     2 |              0 |       10      |        1        |       437 |            48 |           60 | False       |\n|  8 |    75 |     1 |              0 |        8      |        1        |       476 |            36 |           50 | False       |\n|  9 |    61 |     2 |              0 |       16      |        1        |       432 |            63 |           69 | False       |\n| 10 |    68 |     1 |              0 |       11.1782 |        1        |       682 |            57 |           52 | False       |\n| 11 |    59 |     2 |              0 |       12      |        1        |       365 |            58 |           63 | False       |\n| 12 |    60 |     2 |              0 |        8      |        0        |       248 |            72 |           63 | False       |\n| 13 |    69 |     2 |              1 |        6      |        1        |       253 |            60 |           74 | False       |\n| 14 |    60 |     1 |              0 |       12      |        0        |       258 |            57 |           70 | False       |\n| 15 |    47 |     2 |              0 |       13      |        1        |       224 |            66 |           76 | False       |\n| 16 |    61 |     2 |              1 |        9      |        1        |       617 |            20 |           67 | True        |\n| 17 |    72 |     2 |              0 |       11      |        0.901961 |       604 |            36 |           61 | True        |\n| 18 |    78 |     1 |              1 |        9      |        1        |       154 |            40 |           60 | True        |\n| 19 |    67 |     2 |              0 |        8      |        1        |       648 |            21 |           50 | True        |\n| 20 |    74 |     2 |              0 |        5      |        1        |       294 |            41 |           58 | True        |"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(df_train_lr.to_markdown()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Vue d'ensemble des données pour l'ensemble d'entraînement de la régression logistique\n",
    "- On voit qu'il manquait deux données dans la catégorie elevated_edge.  Elles ont été remplacées par la 'moyenne'.  Est-ce adéquat?  Cela pose des problèmes lorsqu'on tente d'extraire les statistiques descriptives des variables catégoriques."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "|             |     Mean |      SDev |\n|:------------|---------:|----------:|\n| age         |  66.2885 |   7.58854 |\n| mh_duration |  11.1782 |   9.57788 |\n| mh_size     | 357.077  | 171.845   |\n| VA_baseline |  50.2115 |  15.2103  |\n| VA_6months  |  65.8269 |  11.7105  |"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_set_continuous_data_stats = get_continuous_data_descriptive_stats(df_train_lr)\n",
    "display(Markdown(train_set_continuous_data_stats.to_markdown()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Résultats de la table 1 pour les variables numériques de l'ensemble d'entraînement de la régression logistique\n",
    "\n",
    "- Les résultats de l'article sont reproduits"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "|                    |   number |   per_cent |\n|:-------------------|---------:|-----------:|\n| F                  |       76 |         73 |\n| M                  |       28 |         27 |\n| lens_absent        |       86 |         83 |\n| lens_present       |       18 |         17 |\n| elevated_edge      |       92 |         88 |\n| no_elevated_edge   |       10 |         10 |\n| 0.9019607843137255 |        2 |          2 |\n| responder          |       52 |         50 |\n| non_responder      |       52 |         50 |"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_set_categorical_data_stats = get_categorical_data_descriptive_stats(df_train_lr)\n",
    "display(Markdown(train_set_categorical_data_stats.to_markdown()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Résultats de la table 1 pour les données catégoriques de l'ensemble d'entraînement\n",
    "\n",
    "- Une fausse catégorie est apparue car des variables elevated_edge absentes ont été remplacées par la moyenne\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121\n"
     ]
    }
   ],
   "source": [
    "total_set = pd.concat([df_train_lr, df_test])\n",
    "print(len(total_set))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Statistiques de l'ensemble total et comparaison entre répondeurs et non-répondeurs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "|             |     Mean |      SDev |\n|:------------|---------:|----------:|\n| age         |  66.6446 |   7.52314 |\n| mh_duration |  11.0566 |   9.0292  |\n| mh_size     | 342.884  | 167.464   |\n| VA_baseline |  50.2975 |  15.576   |\n| VA_6months  |  65.8512 |  11.6702  |"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_set_continuous_data_stats = get_continuous_data_descriptive_stats(total_set)\n",
    "display(Markdown(total_set_continuous_data_stats.to_markdown()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Résultats de la table 1 pour les données numériques de l'ensemble total\n",
    "\n",
    "- Une anomalie semble s'être glissée dans l'écart-type de l'âge"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "|                    |   number |   per_cent |\n|:-------------------|---------:|-----------:|\n| F                  |       88 |         73 |\n| M                  |       33 |         27 |\n| lens_absent        |       99 |         82 |\n| lens_present       |       22 |         18 |\n| elevated_edge      |      105 |         87 |\n| no_elevated_edge   |       14 |         12 |\n| 0.9019607843137255 |        2 |          2 |\n| non_responder      |       61 |         50 |\n| responder          |       60 |         50 |"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_set_categorical_data_stats = get_categorical_data_descriptive_stats(total_set)\n",
    "display(Markdown(total_set_categorical_data_stats.to_markdown()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Résultats de la table 1 pour les données catégoriques de l'ensemble total\n",
    "\n",
    "- Présence de la même anomalie pour la catégorie elevated_edge"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "|             |   Mean_resp |   SD_resp |   Mean_nonresp |   SD_nonresp |\n|:------------|------------:|----------:|---------------:|-------------:|\n| age         |     66.8    |   7.75428 |        66.4918 |      7.34988 |\n| mh_duration |     11.4582 |  11.4477  |        10.6616 |      5.81962 |\n| mh_size     |    393.85   | 184.593   |       292.754  |    132.019   |\n| VA_baseline |     41.8667 |  15.5449  |        58.5902 |     10.3253  |\n| VA_6months  |     70      |   9.25715 |        61.7705 |     12.4089  |"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_set_non_responder, total_set_responder = [x for _, x in total_set.groupby(total_set['responder'])]\n",
    "\n",
    "responders_continuous_data_stats = get_continuous_data_descriptive_stats(total_set_responder)\n",
    "responders_continuous_data_stats.rename({'Mean': 'Mean_resp', 'SDev': 'SD_resp'}, axis=1, inplace=True)\n",
    "non_responders_continuous_data_stats = get_continuous_data_descriptive_stats(total_set_non_responder)\n",
    "non_responders_continuous_data_stats.rename({'Mean': 'Mean_nonresp', 'SDev': 'SD_nonresp'}, axis=1, inplace=True)\n",
    "\n",
    "rvsnonr_continuous_data_stats = pd.concat([responders_continuous_data_stats, non_responders_continuous_data_stats], axis=1)\n",
    "display(Markdown(rvsnonr_continuous_data_stats.to_markdown()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Table 2: Comparaison des répondeurs vs non-répondeurs pour les variables numériques\n",
    "\n",
    "- L'écart-type pour l'âge dans l'article semble avoir spontanément été multiplié par deux"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "|                    |   number |   per_cent |   number |   per_cent |\n|:-------------------|---------:|-----------:|---------:|-----------:|\n| F                  |       47 |         78 |       41 |         67 |\n| M                  |       13 |         22 |       20 |         33 |\n| lens_absent        |       45 |         75 |       54 |         89 |\n| lens_present       |       15 |         25 |        7 |         11 |\n| elevated_edge      |       54 |         90 |       51 |         84 |\n| no_elevated_edge   |        5 |          8 |        9 |         15 |\n| 0.9019607843137255 |        1 |          2 |        1 |          2 |\n| responder          |       60 |        100 |      nan |        nan |\n| non_responder      |      nan |        nan |       61 |        100 |"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "responders_categorical_data_stats = get_categorical_data_descriptive_stats(total_set_responder)\n",
    "responders_categorical_data_stats.rename({'Mean': 'Mean_resp', 'SDev': 'SD_resp'}, axis=1, inplace=True)\n",
    "nonresponders_categorical_data_stats = get_categorical_data_descriptive_stats(total_set_non_responder)\n",
    "nonresponders_categorical_data_stats.rename({'Mean': 'Mean_nonresp', 'SDev': 'SD_nonresp'}, axis=1, inplace=True)\n",
    "rvsnr_categorical_data_stats = pd.concat([responders_categorical_data_stats, nonresponders_categorical_data_stats], axis=1)\n",
    "display(Markdown(rvsnr_categorical_data_stats.to_markdown()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Table 2 comparaison des répondeurs vs non-répondeurs pour les données catégoriques"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Expérience de régression logistique sur l'ensemble d'entraînement"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Normalisation des données et définition des variables dépendantes et indépendantes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "|    |   pseudophakic |   mh_duration |    mh_size |   VA_baseline |\n|---:|---------------:|--------------:|-----------:|--------------:|\n|  0 |              0 |    -0.853865  | -0.122651  |     0.512052  |\n|  1 |              0 |     3.74005   |  1.13429   |    -1.13157   |\n|  2 |              0 |    -0.331829  |  2.3505    |    -2.64371   |\n|  3 |              0 |    -0.227422  |  0.639663  |    -0.539867  |\n|  4 |              0 |    -0.436236  | -0.215757  |     0.709287  |\n|  5 |              0 |    -0.331829  | -1.18756   |     1.03801   |\n|  6 |              1 |    -0.436236  |  0.936441  |     0.183327  |\n|  7 |              1 |    -0.0186072 |  1.82678   |     0.183327  |\n|  8 |              1 |    -0.436236  | -0.541632  |    -0.145398  |\n|  9 |              0 |     0.81665   | -1.30395   |     0.512052  |\n| 10 |              1 |    -0.749458  |  1.67548   |    -1.00008   |\n| 11 |              1 |    -0.227422  |  0.313788  |    -0.145398  |\n| 12 |              0 |     1.02546   |  0.121755  |    -0.145398  |\n| 13 |              0 |     0         | -0.221577  |     0.840777  |\n| 14 |              0 |     0.0858    | -0.681292  |     0.512052  |\n| 15 |              0 |    -0.436236  | -0.0295436 |     0.577797  |\n| 16 |              1 |    -0.958272  | -0.396152  |     0.577797  |\n| 17 |              0 |    -0.436236  | -0.867506  |     0.117582  |\n| 18 |              0 |    -0.749458  | -1.56581   |    -0.0796526 |\n| 19 |              0 |    -0.436236  |  2.624     |    -0.934337  |\n| 20 |              0 |     0.712243  | -0.867506  |     0.117582  |\n| 21 |              0 |    -0.749458  |  0.0344675 |    -0.934337  |\n| 22 |              0 |     0.607836  |  0.546556  |    -0.605612  |\n| 23 |              0 |     0.0858    | -0.739484  |     0.512052  |\n| 24 |              0 |    -0.436236  | -1.44942   |     0.840777  |\n| 25 |              0 |    -0.227422  |  0.0635634 |     0.183327  |\n| 26 |              0 |    -0.0186072 | -1.01299   |     0.840777  |\n| 27 |              0 |    -0.123014  | -0.55327   |     0.446307  |\n| 28 |              0 |    -0.436236  | -0.634739  |    -0.0139076 |\n| 29 |              0 |    -0.0186072 |  0.110117  |     0.577797  |\n| 30 |              0 |     0.0858    | -0.0877354 |     0.775032  |\n| 31 |              0 |     2.90479   |  0.901526  |    -0.474122  |\n| 32 |              0 |     0.712243  | -0.727846  |     1.8927    |\n| 33 |              0 |    -0.749458  | -1.24575   |     1.03801   |\n| 34 |              0 |    -0.123014  | -1.42615   |     1.1695    |\n| 35 |              0 |    -0.331829  | -1.13519   |    -0.0796526 |\n| 36 |              1 |    -0.331829  | -1.16428   |     0.446307  |\n| 37 |              0 |     0.190207  | -1.05372   |     0.972267  |\n| 38 |              0 |    -0.123014  |  0.44181   |     0.0518374 |\n| 39 |              0 |    -0.64505   |  0.808419  |     0.446307  |\n| 40 |              0 |    -0.64505   |  0.453449  |     0.906522  |\n| 41 |              0 |    -0.331829  | -0.239034  |    -0.145398  |\n| 42 |              0 |    -0.331829  | -0.634739  |    -0.474122  |\n| 43 |              0 |     0.712243  | -0.902421  |    -0.934337  |\n| 44 |              0 |    -0.227422  | -0.541632  |     0.775032  |\n| 45 |              0 |    -0.749458  | -0.239034  |     0.0518374 |\n| 46 |              0 |     0.607836  |  0.628024  |    -0.0796526 |\n| 47 |              0 |     0.0858    | -0.867506  |     0.380562  |\n| 48 |              0 |    -0.436236  |  0.44763   |    -0.0139076 |\n| 49 |              0 |     0.0858    |  1.05864   |    -0.934337  |\n| 50 |              1 |    -0.0186072 | -1.14683   |     0.643542  |\n| 51 |              0 |    -0.436236  |  0.133394  |    -0.0796526 |\n| 52 |              0 |     0.190207  |  0.395257  |     0.643542  |\n| 53 |              0 |    -0.540643  | -1.05372   |     1.30099   |\n| 54 |              0 |    -0.540643  | -0.745303  |     0.972267  |\n| 55 |              0 |    -0.540643  | -1.61236   |     0.840777  |\n| 56 |              0 |     0.190207  | -0.978071  |     1.30099   |\n| 57 |              0 |    -0.958272  | -1.51925   |     0.972267  |\n| 58 |              1 |    -0.540643  | -0.448525  |     0.972267  |\n| 59 |              1 |    -0.853865  |  0.249777  |     1.8927    |\n| 60 |              0 |    -0.540643  |  0.482545  |     1.1695    |\n| 61 |              0 |     0         | -0.873325  |     0.643542  |\n| 62 |              0 |    -0.749458  | -0.506717  |     0.972267  |\n| 63 |              0 |     1.02546   | -0.681292  |     0.840777  |\n| 64 |              1 |     0.0858    |  0.680397  |     1.30099   |\n| 65 |              0 |     0.190207  | -0.780218  |     0.840777  |\n| 66 |              0 |    -0.64505   |  0.820057  |    -0.671357  |\n| 67 |              0 |     1.33869   |  1.36706   |    -2.64371   |\n| 68 |              0 |    -0.331829  | -1.36796   |    -0.671357  |\n| 69 |              0 |    -0.123014  |  2.06536   |    -2.64371   |\n| 70 |              0 |    -0.227422  |  1.97226   |    -0.474122  |\n| 71 |              0 |    -0.436236  | -0.401971  |    -1.06583   |\n| 72 |              0 |    -0.958272  | -0.681292  |    -0.671357  |\n| 73 |              0 |     0.399022  |  1.25068   |    -0.474122  |\n| 74 |              1 |    -0.436236  |  0.174128  |    -0.474122  |\n| 75 |              1 |     6.66345   |  1.57073   |    -2.64371   |\n| 76 |              0 |     0.503429  |  1.8326    |    -0.474122  |\n| 77 |              0 |    -0.227422  |  1.2274    |    -0.605612  |\n| 78 |              0 |    -0.436236  |  0.750227  |    -1.92051   |\n| 79 |              0 |    -0.749458  | -0.076097  |    -0.671357  |\n| 80 |              1 |    -0.227422  |  0.0635634 |    -1.92051   |\n| 81 |              0 |     1.33869   |  0.750227  |    -2.64371   |\n| 82 |              0 |     2.80039   |  0.907345  |    -0.0796526 |\n|  0 |              0 |    -0.64505   | -0.681292  |    -0.0796526 |\n|  1 |              0 |    -0.123014  | -1.10027   |     0.512052  |\n|  2 |              0 |    -0.540643  |  0.110117  |    -0.145398  |\n|  3 |              1 |    -0.64505   | -0.320503  |     0.512052  |\n|  4 |              0 |    -0.331829  | -0.186662  |    -0.671357  |\n|  5 |              0 |     0.294614  | -1.12355   |     0.709287  |\n|  6 |              0 |     1.33869   |  0.988814  |    -0.211143  |\n|  7 |              0 |    -0.123014  |  0.465087  |    -0.145398  |\n|  8 |              0 |    -0.331829  |  0.692035  |    -0.934337  |\n|  9 |              0 |     0.503429  |  0.435991  |     0.840777  |\n| 10 |              0 |     0         |  1.89079   |     0.446307  |\n| 11 |              0 |     0.0858    |  0.0461059 |     0.512052  |\n| 12 |              0 |    -0.331829  | -0.634739  |     1.43248   |\n| 13 |              1 |    -0.540643  | -0.605643  |     0.643542  |\n| 14 |              0 |     0.0858    | -0.576547  |     0.446307  |\n| 15 |              0 |     0.190207  | -0.774399  |     1.03801   |\n| 16 |              1 |    -0.227422  |  1.51254   |    -1.98626   |\n| 17 |              0 |    -0.0186072 |  1.43689   |    -0.934337  |\n| 18 |              1 |    -0.227422  | -1.18174   |    -0.671357  |\n| 19 |              0 |    -0.331829  |  1.69294   |    -1.92051   |\n| 20 |              0 |    -0.64505   | -0.367056  |    -0.605612  |"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "|    |   responder |\n|---:|------------:|\n|  0 |           1 |\n|  1 |           1 |\n|  2 |           1 |\n|  3 |           1 |\n|  4 |           1 |\n|  5 |           1 |\n|  6 |           1 |\n|  7 |           1 |\n|  8 |           1 |\n|  9 |           1 |\n| 10 |           1 |\n| 11 |           1 |\n| 12 |           1 |\n| 13 |           1 |\n| 14 |           1 |\n| 15 |           1 |\n| 16 |           1 |\n| 17 |           1 |\n| 18 |           1 |\n| 19 |           1 |\n| 20 |           1 |\n| 21 |           1 |\n| 22 |           1 |\n| 23 |           1 |\n| 24 |           0 |\n| 25 |           0 |\n| 26 |           0 |\n| 27 |           0 |\n| 28 |           0 |\n| 29 |           0 |\n| 30 |           0 |\n| 31 |           0 |\n| 32 |           0 |\n| 33 |           0 |\n| 34 |           0 |\n| 35 |           0 |\n| 36 |           0 |\n| 37 |           0 |\n| 38 |           0 |\n| 39 |           0 |\n| 40 |           0 |\n| 41 |           0 |\n| 42 |           0 |\n| 43 |           0 |\n| 44 |           0 |\n| 45 |           0 |\n| 46 |           0 |\n| 47 |           0 |\n| 48 |           0 |\n| 49 |           0 |\n| 50 |           0 |\n| 51 |           0 |\n| 52 |           0 |\n| 53 |           0 |\n| 54 |           0 |\n| 55 |           0 |\n| 56 |           0 |\n| 57 |           0 |\n| 58 |           0 |\n| 59 |           0 |\n| 60 |           0 |\n| 61 |           0 |\n| 62 |           0 |\n| 63 |           0 |\n| 64 |           0 |\n| 65 |           0 |\n| 66 |           1 |\n| 67 |           1 |\n| 68 |           1 |\n| 69 |           1 |\n| 70 |           1 |\n| 71 |           1 |\n| 72 |           1 |\n| 73 |           1 |\n| 74 |           1 |\n| 75 |           1 |\n| 76 |           1 |\n| 77 |           1 |\n| 78 |           1 |\n| 79 |           1 |\n| 80 |           1 |\n| 81 |           1 |\n| 82 |           1 |\n|  0 |           1 |\n|  1 |           1 |\n|  2 |           1 |\n|  3 |           1 |\n|  4 |           1 |\n|  5 |           1 |\n|  6 |           0 |\n|  7 |           0 |\n|  8 |           0 |\n|  9 |           0 |\n| 10 |           0 |\n| 11 |           0 |\n| 12 |           0 |\n| 13 |           0 |\n| 14 |           0 |\n| 15 |           0 |\n| 16 |           1 |\n| 17 |           1 |\n| 18 |           1 |\n| 19 |           1 |\n| 20 |           1 |"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def normalise_data(df):\n",
    "    for variable in ['mh_duration', 'mh_size', 'VA_baseline']:\n",
    "        moy = df[variable].mean()\n",
    "        std = df[variable].std()\n",
    "        df[variable] = (df[variable] - moy) / std\n",
    "\n",
    "# Préparation des données\n",
    "X = df_train_lr.copy().drop(['responder', 'age', 'sex', 'VA_6months', 'elevated_edge'], axis=1)\n",
    "normalise_data(X)\n",
    "y = df_train_lr['responder'].copy()\n",
    "\n",
    "display(Markdown(X.to_markdown()))\n",
    "display(Markdown(y.to_markdown()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sélection du modèle de régression et entraînement"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegressionCV(cv=10)"
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_exp1 = LogisticRegressionCV(cv=10)\n",
    "model_exp1.fit(X, y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tests du modèle de régression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "|       |   Train set |\n|:------|------------:|\n| acc   |    0.721154 |\n| F1    |    0.712871 |\n| auroc |    0.818787 |\n| SP    |    0.75     |\n| SN    |    0.692308 |\n| NPV   |    0.709091 |\n| PPV   |    0.734694 |"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "|       |   Test set |\n|:------|-----------:|\n| acc   |   0.764706 |\n| F1    |   0.75     |\n| auroc |   0.875    |\n| SP    |   0.777778 |\n| SN    |   0.75     |\n| NPV   |   0.777778 |\n| PPV   |   0.75     |"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tester_le_modele(mod, X_test, y_test):\n",
    "\n",
    "    scores_tests = {}\n",
    "    resultats_tests = {}\n",
    "\n",
    "    # On génère les prédictions du modèle\n",
    "    y_pred = pd.Series(mod.predict(X_test))\n",
    "    resultats_tests['probabilites'] = mod.predict_proba(X_test)\n",
    "\n",
    "    # À partir des prédictions on compile les matrices de confusions, et ROC\n",
    "    resultats_tests['faux_pos'], resultats_tests['vrais_pos'], resultats_tests['seuils'] = \\\n",
    "        metrics.roc_curve(y_true=y_test, y_score=resultats_tests['probabilites'][:, 1], pos_label=True)\n",
    "    resultats_tests['confusion_matrix'] = metrics.confusion_matrix(y_test, y_pred)\n",
    "    resultats_tests['coefficients'] = model.coef_\n",
    "\n",
    "    # On accumule les scores dans un dict\n",
    "    scores_tests['acc'] = metrics.accuracy_score(y_test, y_pred)\n",
    "    scores_tests['F1'] = metrics.f1_score(y_test, y_pred, pos_label=True)\n",
    "    scores_tests['auroc'] = metrics.auc(resultats_tests['faux_pos'], resultats_tests['vrais_pos'])\n",
    "\n",
    "    # Sensibilité, spécificité etc à partir de la matrice de confusion\n",
    "    negatives = resultats_tests['confusion_matrix'][0]\n",
    "    positives = resultats_tests['confusion_matrix'][1]\n",
    "\n",
    "    scores_tests['SP'] = negatives[0] / (negatives[0] + negatives[1])\n",
    "    scores_tests['SN'] = positives[1] / (positives[0] + positives[1])\n",
    "    scores_tests['NPV'] = negatives[0] / (negatives[0] + positives[0])\n",
    "    scores_tests['PPV'] = positives[1] / (negatives[1] + positives[1])\n",
    "\n",
    "    return pd.Series(scores_tests), resultats_tests['faux_pos'], resultats_tests['vrais_pos'], resultats_tests['seuils']\n",
    "\n",
    "# Auto test avec le set d'entraînement\n",
    "stats_exp_1_train, fpr, tpr, thr = tester_le_modele(model_exp1, X, y)\n",
    "stats_exp_1_train.rename('Train set', inplace=True)\n",
    "\n",
    "display(Markdown(stats_exp_1_train.to_markdown()))\n",
    "\n",
    "# Véritable test avec le set de test: préparation des données test\n",
    "X_test = df_test.copy().drop(['responder', 'age', 'sex', 'VA_6months', 'elevated_edge'], axis=1)\n",
    "normalise_data(X_test)\n",
    "y_test = df_test['responder'].copy()\n",
    "\n",
    "stats_exp_1, fpr_exp1, tpr_exp1, thr_exp1 = tester_le_modele(model_exp1, X_test, y_test)\n",
    "stats_exp_1.rename('Test set', inplace=True)\n",
    "\n",
    "display(Markdown(stats_exp_1.to_markdown()))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(3, 1, 'AUROC=0.875')"
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(fpr_exp1, tpr_exp1, color=\"blue\", lw=2, label=f\"AUROC={stats_exp_1['auroc']}\")\n",
    "plt.xlabel(\"Vrais positifs\")\n",
    "plt.ylabel(\"Faux positifs\")\n",
    "plt.annotate(f\"AUROC={stats_exp_1['auroc']}\", xy=(3,1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Régression logistique: expérience de cross-validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Résultats de la crossvalidation sur 25 runs: training set"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "|       |     Mean |       Std |\n|:------|---------:|----------:|\n| acc   | 0.719067 | 0.0699836 |\n| F1    | 0.720903 | 0.0694022 |\n| auroc | 0.826432 | 0.0500778 |\n| SP    | 0.701282 | 0.150948  |\n| SN    | 0.736667 | 0.117063  |\n| NPV   | 0.741473 | 0.0897081 |\n| PPV   | 0.721524 | 0.0905628 |"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Résultats de la crossvalidation sur 25 runs: testing set"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "|       |     Mean |       Std |\n|:------|---------:|----------:|\n| acc   | 0.761989 | 0.0204439 |\n| F1    | 0.75748  | 0.0218632 |\n| auroc | 0.84588  | 0.0134039 |\n| SP    | 0.773724 | 0.0229155 |\n| SN    | 0.75     | 0.0268957 |\n| NPV   | 0.759113 | 0.0216893 |\n| PPV   | 0.76541  | 0.0212475 |"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Expérience de cross-validation en régression logistique\n",
    "count = 0\n",
    "crossval_test_scores = pd.DataFrame()\n",
    "crossval_train_scores = pd.DataFrame()\n",
    "\n",
    "# Préparation des données\n",
    "X_crossval = total_set.copy().drop(['responder', 'age', 'sex', 'VA_6months', 'elevated_edge'], axis=1)\n",
    "normalise_data(X_crossval)\n",
    "y_crossval = total_set['responder'].copy()\n",
    "\n",
    "# Expérience de cross-validation\n",
    "for n_exp in range(5):\n",
    "\n",
    "    # Définition des splits\n",
    "    folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=n_exp)\n",
    "    groupes = folds.split(X_crossval, y_crossval)\n",
    "\n",
    "    # Pour chaque split...\n",
    "    for train_index, test_index in groupes:\n",
    "\n",
    "        # Sélection du modèle\n",
    "        model = LogisticRegressionCV(cv=10)\n",
    "\n",
    "        # Initialisation des ensembles selon les splits\n",
    "        X_train_CV, X_test_CV = X_crossval.iloc[train_index, :], X_crossval.iloc[test_index, :]\n",
    "        y_train_CV, y_test_CV = y_crossval.iloc[train_index], y_crossval.iloc[test_index]\n",
    "\n",
    "        # Entraînement\n",
    "        model.fit(X_train_CV, y_train_CV)\n",
    "\n",
    "        # Accumulation des données métriques\n",
    "        test_stats, test_fpr, test_tpr, test_thr = tester_le_modele(model, X_test_CV, y_test_CV)\n",
    "        train_stats, train_fpr, train_tpr, train_thr = tester_le_modele(model, X_train_CV, y_train_CV)\n",
    "        print(\".\", end=\"\")\n",
    "        crossval_test_scores = pd.concat([crossval_test_scores, test_stats], axis=1)\n",
    "        crossval_train_scores = pd.concat([crossval_train_scores, train_stats], axis=1)\n",
    "        count += 1\n",
    "\n",
    "# Mise en forme des résultats accumulés\n",
    "crossval_test_scores = crossval_test_scores.transpose()\n",
    "crossval_train_scores = crossval_train_scores.transpose()\n",
    "\n",
    "stats_test_crossval = pd.DataFrame([crossval_test_scores.mean(axis=0, skipna=True), crossval_test_scores.std(axis=0, skipna=True)]).transpose()\n",
    "stats_test_crossval.rename(columns={0:'Mean', 1: 'Std'}, inplace=True)\n",
    "\n",
    "stats_train_crossval = pd.DataFrame([crossval_train_scores.mean(axis=0, skipna=True), crossval_train_scores.std(axis=0, skipna=True)]).transpose()\n",
    "stats_train_crossval.rename(columns={0:'Mean', 1: 'Std'}, inplace=True)\n",
    "\n",
    "print(\"\\n\")\n",
    "display(Markdown(\"### Résultats de la crossvalidation sur 25 runs: training set\"))\n",
    "display(Markdown(stats_test_crossval.to_markdown()))\n",
    "display(Markdown(\"### Résultats de la crossvalidation sur 25 runs: testing set\"))\n",
    "display(Markdown(stats_train_crossval.to_markdown()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Statistiques pour l'expérience de crossvalidation: 25 runs au total"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.figure()\n",
    "\n",
    "# Bâtir les courbes pour chaque exécution\n",
    "for i in range(len(self.stats)):\n",
    "    results = self.stats[i]\n",
    "    plt.plot(results[\"faux_pos\"], results[\"vrais_pos\"], color=\"grey\", lw=1, label=f\"Run {i}: AUROC = {results['auroc']:.2f}\")\n",
    "\n",
    "fpr_moyen, tpr_moyen = self.construire_courbe_ROC_moyenne ()\n",
    "plt.plot(fpr_moyen, tpr_moyen, color=\"red\", lw=2, linestyle = \"dotted\", label=f\"Moyenne: AUROC = {self.lire_aurocs().mean()}\")\n",
    "\n",
    "# Bâtir la courbe de référence\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
    "\n",
    "# Paramètres du graphe\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"Faux positifs\")\n",
    "plt.ylabel(\"Vrais positifs\")\n",
    "plt.title(\"Courbe récepteur-opérateur\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}